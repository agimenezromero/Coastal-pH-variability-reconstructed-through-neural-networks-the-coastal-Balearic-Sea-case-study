{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ = \"LSTM\"\n",
    "\n",
    "folders = \"/Ensambles/%s/\" % type_\n",
    "\n",
    "slopes_f = []\n",
    "intercepts_f = []\n",
    "\n",
    "train_errors_f = []\n",
    "val_errors_f = []\n",
    "\n",
    "N_epochs_f = []\n",
    "training_times_f = []\n",
    "\n",
    "for filename in os.listdir(os.getcwd() + folders):\n",
    "    \n",
    "    slopes, intercepts, train_errors, val_errors, N_epochs, training_times = np.loadtxt(os.getcwd() + folders + filename, unpack=True)\n",
    "    \n",
    "    slopes_f.append(slopes)\n",
    "    intercepts_f.append(intercepts)\n",
    "\n",
    "    train_errors_f.append(train_errors)\n",
    "    val_errors_f.append(val_errors)\n",
    "\n",
    "    N_epochs_f.append(N_epochs)\n",
    "    training_times_f.append(training_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_f = np.array(slopes_f).flatten()\n",
    "intercepts_f = np.array(intercepts_f).flatten()\n",
    "\n",
    "train_errors_f = np.array(train_errors_f).flatten()\n",
    "val_errors_f = np.array(val_errors_f).flatten()\n",
    "\n",
    "N_epochs_f = np.array(N_epochs_f).flatten()\n",
    "training_times_f = np.array(training_times_f).flatten()\n",
    "\n",
    "mean_slope = np.round(np.mean(slopes_f), 4)\n",
    "mean_intercept = np.round(np.mean(intercepts_f), 2)\n",
    "\n",
    "mean_train_err = np.round(np.mean(train_errors_f), 2)\n",
    "mean_val_err = np.round(np.mean(val_errors_f), 2)\n",
    "\n",
    "mean_epochs = np.round(np.mean(N_epochs_f), 0)\n",
    "mean_time = np.round(np.mean(training_times_f), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8*2, 6*3))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "\n",
    "plt.hist(slopes_f, bins=30);\n",
    "plt.axvline([mean_slope], color='r', lw=3, label=\"Mean: %s\" % mean_slope)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Slope\", fontsize=30)\n",
    "plt.ylabel(\"Count\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "\n",
    "plt.hist(intercepts_f, bins=30);\n",
    "plt.axvline([mean_intercept], color='r', lw=3, label=\"Mean: %s\" % mean_intercept)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Intercept\", fontsize=30)\n",
    "plt.ylabel(\"Count\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "\n",
    "plt.hist(train_errors_f, bins=30);\n",
    "plt.axvline([mean_train_err], color='r', lw=3, label=\"Mean: %s\" % mean_train_err)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Training error [%]\", fontsize=30)\n",
    "plt.ylabel(\"Count\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "\n",
    "plt.hist(val_errors_f, bins=30);\n",
    "plt.axvline([mean_val_err], color='r', lw=3, label=\"Mean: %s\" % mean_val_err)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Validation error [%]\", fontsize=30)\n",
    "plt.ylabel(\"Count\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "\n",
    "plt.hist(N_epochs_f, bins=30);\n",
    "plt.axvline([mean_epochs], color='r', lw=3, label=\"Mean: %s\" % mean_epochs)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Training epochs\", fontsize=30)\n",
    "plt.ylabel(\"Count\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "\n",
    "plt.hist(training_times_f, bins=30);\n",
    "plt.axvline([mean_time], color='r', lw=3, label=\"Mean: %s\" % mean_time)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Training time [s]\", fontsize=30)\n",
    "plt.ylabel(\"Count\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.savefig(\"Statistics_%s.png\" % type_, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"RNN\", \"LSTM\", \"BI_LSTM\", \"BI_GRU\"]\n",
    "\n",
    "SLOPES = []\n",
    "INTERCEPTS = []\n",
    "\n",
    "TRAIN_ERR = []\n",
    "VAL_ERR = []\n",
    "\n",
    "EPOCHS = []\n",
    "TIMES = []\n",
    "\n",
    "ERR_SLOPES = []\n",
    "ERR_INTERCEPTS = []\n",
    "\n",
    "ERR_TRAIN_ERR = []\n",
    "ERR_VAL_ERR = []\n",
    "\n",
    "ERR_EPOCHS = []\n",
    "ERR_TIMES = []\n",
    "\n",
    "for type_ in types:\n",
    "\n",
    "    folders = \"/Ensambles/%s/\" % type_\n",
    "\n",
    "    slopes_f = []\n",
    "    intercepts_f = []\n",
    "\n",
    "    train_errors_f = []\n",
    "    val_errors_f = []\n",
    "\n",
    "    N_epochs_f = []\n",
    "    training_times_f = []\n",
    "\n",
    "    for filename in os.listdir(os.getcwd() + folders):\n",
    "\n",
    "        slopes, intercepts, train_errors, val_errors, N_epochs, training_times = np.loadtxt(os.getcwd() + folders + filename, unpack=True)\n",
    "\n",
    "        slopes_f.append(slopes)\n",
    "        intercepts_f.append(intercepts)\n",
    "\n",
    "        train_errors_f.append(train_errors)\n",
    "        val_errors_f.append(val_errors)\n",
    "\n",
    "        N_epochs_f.append(N_epochs)\n",
    "        training_times_f.append(training_times)\n",
    "        \n",
    "    slopes_f = np.array(slopes_f).flatten()\n",
    "    intercepts_f = np.array(intercepts_f).flatten()\n",
    "\n",
    "    train_errors_f = np.array(train_errors_f).flatten()\n",
    "    val_errors_f = np.array(val_errors_f).flatten()\n",
    "\n",
    "    N_epochs_f = np.array(N_epochs_f).flatten()\n",
    "    training_times_f = np.array(training_times_f).flatten()\n",
    "\n",
    "    mean_slope = np.round(np.mean(slopes_f), 4)\n",
    "    mean_intercept = np.round(np.mean(intercepts_f), 2)\n",
    "\n",
    "    mean_train_err = np.round(np.mean(train_errors_f), 2)\n",
    "    mean_val_err = np.round(np.mean(val_errors_f), 2)\n",
    "\n",
    "    mean_epochs = np.round(np.mean(N_epochs_f), 0)\n",
    "    mean_time = np.round(np.mean(training_times_f), 2)\n",
    "    \n",
    "    err_slope = np.std(slopes_f)\n",
    "    err_intercept = np.std(intercepts_f)\n",
    "    \n",
    "    err_train_err = np.std(train_errors_f)\n",
    "    err_val_err = np.std(val_errors_f)\n",
    "    \n",
    "    err_epochs = np.std(N_epochs_f)\n",
    "    err_times = np.std(training_times_f)\n",
    "    \n",
    "    SLOPES.append(mean_slope)\n",
    "    INTERCEPTS.append(mean_intercept)\n",
    "    \n",
    "    TRAIN_ERR.append(mean_train_err)\n",
    "    VAL_ERR.append(mean_val_err)\n",
    "    \n",
    "    EPOCHS.append(mean_epochs)\n",
    "    TIMES.append(mean_time)\n",
    "    \n",
    "    ERR_SLOPES.append(err_slope)\n",
    "    ERR_INTERCEPTS.append(err_intercept)\n",
    "    \n",
    "    ERR_TRAIN_ERR.append(err_train_err)\n",
    "    ERR_VAL_ERR.append(err_val_err)\n",
    "    \n",
    "    ERR_EPOCHS.append(err_epochs)\n",
    "    ERR_TIMES.append(err_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPES_F = [\"%.4f +- %.5f\" % (SLOPES[i], ERR_SLOPES[i]) for i in range(4)]\n",
    "INTERCEPTS_F = [\"%.4f +- %.5f\" % (INTERCEPTS[i], ERR_INTERCEPTS[i]) for i in range(4)]\n",
    "\n",
    "TRAIN_ERR_F = [\"%.4f +- %.5f\" % (TRAIN_ERR[i], ERR_TRAIN_ERR[i]) for i in range(4)]\n",
    "VAL_ERR_F = [\"%.4f +- %.5f\" % (VAL_ERR[i], ERR_VAL_ERR[i]) for i in range(4)]\n",
    "\n",
    "EPOCHS_F = [\"%.4f +- %.5f\" % (EPOCHS[i], ERR_EPOCHS[i]) for i in range(4)]\n",
    "TIMES_F = [\"%.4f +- %.5f\" % (TIMES[i], ERR_TIMES[i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Slope':SLOPES_F, 'Intercept':INTERCEPTS_F, \n",
    "                   'Training error':TRAIN_ERR_F, 'Validation error':VAL_ERR_F,\n",
    "                   'Training epochs':EPOCHS_F, 'Training time':TIMES_F})\n",
    "\n",
    "df.index = types\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Statistics_RNNs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
