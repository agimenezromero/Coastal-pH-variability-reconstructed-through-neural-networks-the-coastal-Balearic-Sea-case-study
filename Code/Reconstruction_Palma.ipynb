{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_dataset(data, n_times, n_features):\n",
    "    \n",
    "    X = np.zeros((len(data)-n_times, n_times, n_features))\n",
    "    Y = np.zeros(len(data)-n_times)\n",
    "\n",
    "    for i in range(len(data) - n_times):\n",
    "\n",
    "        X[i] = data[i:n_times+i, 0:n_features]\n",
    "        Y[i] = data[n_times+i, -1]\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "def RNN_dataset_pred(data, n_times, n_features):\n",
    "    \n",
    "    X = np.zeros((len(data)-n_times, n_times, n_features))\n",
    "\n",
    "    for i in range(len(data) - n_times):\n",
    "\n",
    "        X[i] = data[i:n_times+i, 0:n_features]\n",
    "        \n",
    "    return X\n",
    "    \n",
    "def preprocessing(data, n_times=24, test_size=0.2):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaled = scaler.fit_transform(data)\n",
    "\n",
    "    data_f = scaled\n",
    "    \n",
    "    n_features = data.shape[-1] - 1\n",
    "\n",
    "    X, Y = RNN_dataset(data_f, n_times, n_features)\n",
    "    \n",
    "    idxs = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        if str(Y[i]) == 'nan':\n",
    "\n",
    "            idxs.append(i)\n",
    "\n",
    "        else:\n",
    "\n",
    "            j = 0\n",
    "\n",
    "            for item in X[i]:\n",
    "\n",
    "                if str(item[0]) == 'nan' or str(item[1]) == 'nan':\n",
    "\n",
    "                    #print(\"nan found\")\n",
    "                    idxs.append(i)\n",
    "\n",
    "                    break\n",
    "\n",
    "                j+= 1\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    X_new = np.zeros((X.shape[0] - len(idxs), X.shape[1], X.shape[2]))\n",
    "    Y_new = np.zeros(len(Y) - len(idxs))\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        if i not in idxs:\n",
    "\n",
    "            X_new[k] = X[i]\n",
    "            Y_new[k] = Y[i]\n",
    "\n",
    "            k += 1\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y_new, test_size=test_size, random_state=4)\n",
    "    \n",
    "    print(\"Training set:\", X_train.shape, \"Test set:\", X_test.shape)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, scaler, X_new, Y_new\n",
    "\n",
    "class PrintCrossPoint(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_cross = \"\"\n",
    "        self.epoch = 0\n",
    "     \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        self.epoch += 1\n",
    "        \n",
    "        logs = logs or {}\n",
    "        \n",
    "        current_train_loss = logs.get(\"loss\")\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "        \n",
    "        if current_val_loss < current_train_loss:\n",
    "            \n",
    "            if self.epoch_cross == \"\":\n",
    "                self.epoch_cross = self.epoch\n",
    "                \n",
    "            #self.model.stop_training = True\n",
    "            \n",
    "    def on_train_end(self, epoch, logs=None):\n",
    "        \n",
    "        print(\"Validation loss higher than training loss from epoch %s!\" % self.epoch_cross)\n",
    "        \n",
    "class StopCrossPoint(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.epoch = 0\n",
    "     \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        self.epoch += 1\n",
    "        \n",
    "        logs = logs or {}\n",
    "        \n",
    "        current_train_loss = logs.get(\"loss\")\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "        \n",
    "        if current_val_loss < current_train_loss:\n",
    "                \n",
    "            print(\"Validation loss higher than training loss from epoch %s!\" % self.epoch)\n",
    "                \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, resample and construct training and validations sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.read_csv(\"Datos pH Baleares/Palma_Bay.csv\")\n",
    "\n",
    "df_f[\"Time\"] = pd.to_datetime(df_f[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_f[\"Time\"], df_f[\"PH\"], s=1)\n",
    "\n",
    "plt.plot(df_f[\"Time\"][(df_f[\"Time\"] > datetime(2019, 8, 15)) & (df_f[\"Time\"] < datetime(2019, 9, 1))], \n",
    "         df_f[\"PH\"][(df_f[\"Time\"] > datetime(2019, 8, 15)) & (df_f[\"Time\"] < datetime(2019, 9, 1))],\n",
    "         color='r')\n",
    "\n",
    "plt.plot(df_f[\"Time\"][(df_f[\"Time\"] > datetime(2020, 6, 15)) & (df_f[\"Time\"] < datetime(2020, 7, 1))], \n",
    "         df_f[\"PH\"][(df_f[\"Time\"] > datetime(2020, 6, 15)) & (df_f[\"Time\"] < datetime(2020, 7, 1))],\n",
    "         color='r')\n",
    "\n",
    "plt.xticks(rotation=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete red points\n",
    "df_final = df_f.drop(df_f[(df_f[\"Time\"] > datetime(2019, 8, 15)) & (df_f[\"Time\"] < datetime(2019, 9, 1))].index)\n",
    "\n",
    "df_final = df_final.drop(df_final[(df_final[\"Time\"] > datetime(2020, 6, 15)) & (df_final[\"Time\"] < datetime(2020, 7, 1))].index)\n",
    "\n",
    "plt.scatter(df_final[\"Time\"], df_final[\"PH\"], s=1)\n",
    "\n",
    "plt.xticks(rotation=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose window size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_resampled = df_final[df_final[\"DO(umol kg-1)\"].astype('str') != 'nan'][[\"Tempertaure (ºC)\", \"DO(umol kg-1)\", \"pHT\"]].values\n",
    "data_resampled = df_final[df_final[\"Oxygen\"].astype('str') != 'nan'][[\"Temperature\", \"Oxygen\", \"Salinity\", \"PH\"]].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, scaler, X_scaled, Y_scaled = preprocessing(data_resampled, n_times=window_size, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_new = df_final[[\"Tempertaure (ºC)\", \"DO(umol kg-1)\"]].values\n",
    "data_new = df_final[[\"Temperature\", \"Oxygen\", \"Salinity\"]].values\n",
    "\n",
    "scaled_new = scaler.min_[0:data_new.shape[-1]] + data_new * scaler.scale_[0:data_new.shape[-1]]\n",
    "\n",
    "n_features = data_new.shape[-1]\n",
    "\n",
    "X_to_predict = RNN_dataset_pred(scaled_new, window_size, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, min_delta=0.00001)\n",
    "callback_2 = StopCrossPoint()\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# design network\n",
    "model_RNN = Sequential()\n",
    "model_RNN.add(SimpleRNN(3, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_RNN.add(Dense(1, activation='sigmoid'))\n",
    "model_RNN.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history_RNN = model_RNN.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=500,\n",
    "    steps_per_epoch=10,S\n",
    "    #batch_size=100, \n",
    "    validation_data=(X_test, Y_test), \n",
    "    verbose=0, \n",
    "    shuffle=False,\n",
    "    callbacks=[callback, callback_2]\n",
    "    )\n",
    "\n",
    "time_elapsed_RNN =  time()-t0\n",
    "epochs_used_RNN = len(history_RNN.history['loss'])\n",
    "\n",
    "final_train_loss_RNN = (history_RNN.history['loss'][-1]*100)\n",
    "final_val_loss_RNN = (history_RNN.history['val_loss'][-1]*100)\n",
    "\n",
    "init_train_loss_RNN = (history_RNN.history['loss'][0]*100)\n",
    "\n",
    "print(\"Finished in\", time_elapsed_RNN, \"s using\", epochs_used_RNN, \"epochs\")\n",
    "\n",
    "y_pred_RNN = model_RNN.predict(X_to_predict)\n",
    "\n",
    "y_pred_noscale_RNN = (y_pred_RNN - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "yhat_RNN = model_RNN.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_RNN.history['loss'], label='Train loss', lw=3)\n",
    "plt.plot(history_RNN.history['val_loss'], label='Validation loss', lw=3)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"Loss (MSE)\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.text(epochs_used_RNN*0.5, init_train_loss_RNN*0.006,\n",
    "         \"Final train loss: %.2f%%\" % final_train_loss_RNN, fontsize=16)\n",
    "plt.text(epochs_used_RNN*0.5, init_train_loss_RNN*0.005,\n",
    "         \"Final val loss: %.2f%%\" % final_val_loss_RNN, fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(Y_scaled, lw=3)\n",
    "plt.plot(yhat_RNN, lw=3)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"pH\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(yhat_RNN, Y_scaled, s=20)\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color='k', lw=3)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"True values\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(df_final.index, df_final[\"PH\"], s=10)\n",
    "plt.scatter(df_final.index[window_size:], y_pred_noscale_RNN, s=1, color='r')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=30)\n",
    "plt.ylabel(\"pH\", fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "#plt.savefig(\"RNN_.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_noscale_RNN[:, 0][df_final[\"PH\"][window_size:].astype('str') != 'nan'] = df_final[\"PH\"][window_size:][df_final[\"PH\"][window_size:].astype('str') != 'nan'].values\n",
    "\n",
    "time_delta = df_final[\"Time\"][window_size:] - df_final[\"Time\"][window_size]\n",
    "\n",
    "time_years = np.array([(item / np.timedelta64(1, 'm')) / (60*24*365) for item in time_delta])\n",
    "\n",
    "Y_TREND = y_pred_noscale_RNN[y_pred_noscale_RNN.astype('str') != 'nan']\n",
    "X_TREND = time_years[y_pred_noscale_RNN[:, 0].astype('str') != 'nan']\n",
    "\n",
    "reg = LinearRegression().fit(X_TREND.reshape(-1,1), Y_TREND)\n",
    "\n",
    "slope_RNN = reg.coef_[0]\n",
    "intercept_RNN = reg.intercept_\n",
    "\n",
    "print(\"m:\", slope_RNN, \"n:\", intercept_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, min_delta=0.00001)\n",
    "callback_2 = StopCrossPoint()     \n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# design network\n",
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(LSTM(3, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_LSTM.add(Dense(1, activation='sigmoid'))\n",
    "model_LSTM.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history_LSTM = model_LSTM.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=500,\n",
    "    steps_per_epoch=10,\n",
    "    #batch_size=100, \n",
    "    validation_data=(X_test, Y_test), \n",
    "    verbose=0, \n",
    "    shuffle=False,\n",
    "    callbacks=[callback, callback_2]\n",
    "    )\n",
    "\n",
    "time_elapsed_LSTM =  time()-t0\n",
    "epochs_used_LSTM = len(history_LSTM.history['loss'])\n",
    "\n",
    "final_train_loss_LSTM = (history_LSTM.history['loss'][-1]*100)\n",
    "final_val_loss_LSTM = (history_LSTM.history['val_loss'][-1]*100)\n",
    "\n",
    "init_train_loss_LSTM = (history_LSTM.history['loss'][0]*100)\n",
    "\n",
    "print(\"Finished in\", time_elapsed_LSTM, \"s using\", epochs_used_LSTM, \"epochs\")\n",
    "\n",
    "y_pred_LSTM = model_LSTM.predict(X_to_predict)\n",
    "\n",
    "y_pred_noscale_LSTM = (y_pred_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "yhat_LSTM = model_LSTM.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_LSTM.history['loss'], label='Train loss', lw=3)\n",
    "plt.plot(history_LSTM.history['val_loss'], label='Validation loss', lw=3)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"Loss (MSE)\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.text(epochs_used_LSTM*0.5, init_train_loss_LSTM*0.006,\n",
    "         \"Final train loss: %.2f%%\" % final_train_loss_LSTM, fontsize=16)\n",
    "plt.text(epochs_used_LSTM*0.5, init_train_loss_LSTM*0.005,\n",
    "         \"Final val loss: %.2f%%\" % final_val_loss_LSTM, fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(Y_scaled, lw=3)\n",
    "plt.plot(yhat_LSTM, lw=3)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"pH\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(yhat_LSTM, Y_scaled, s=20)\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color='k', lw=3)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"True values\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(df_final.index, df_final[\"PH\"], s=10)\n",
    "plt.scatter(df_final.index[window_size:], y_pred_noscale_LSTM, s=1, color='r')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=30)\n",
    "plt.ylabel(r\"$pH_T$\", fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_noscale_LSTM[:, 0][df_final[\"PH\"][window_size:].astype('str') != 'nan'] = df_final[\"PH\"][window_size:][df_final[\"PH\"][window_size:].astype('str') != 'nan'].values\n",
    "\n",
    "time_delta = df_final[\"Time\"][window_size:] - df_final[\"Time\"][window_size]\n",
    "\n",
    "time_years = np.array([(item / np.timedelta64(1, 'm')) / (60*24*365) for item in time_delta])\n",
    "\n",
    "Y_TREND = y_pred_noscale_LSTM[y_pred_noscale_LSTM.astype('str') != 'nan']\n",
    "X_TREND = time_years[y_pred_noscale_LSTM[:, 0].astype('str') != 'nan']\n",
    "\n",
    "reg = LinearRegression().fit(X_TREND.reshape(-1,1), Y_TREND)\n",
    "\n",
    "slope_LSTM = reg.coef_[0]\n",
    "intercept_LSTM = reg.intercept_\n",
    "\n",
    "print(\"m:\", slope_LSTM, \"n:\", intercept_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_train_loss_BI_LSTM = 100\n",
    "\n",
    "#while final_train_loss_BI_LSTM > 0.4:\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, min_delta=0.00001)\n",
    "callback_2 = StopCrossPoint()     \n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# design network\n",
    "model_BI_LSTM = Sequential()\n",
    "model_BI_LSTM.add(Bidirectional(LSTM(3, activation='tanh',\n",
    "                              input_shape=(X_train.shape[1], X_train.shape[2]))))\n",
    "model_BI_LSTM.add(Dense(1, activation='sigmoid'))\n",
    "model_BI_LSTM.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history_BI_LSTM = model_BI_LSTM.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=500,\n",
    "    steps_per_epoch=10,\n",
    "    #batch_size=100, \n",
    "    validation_data=(X_test, Y_test), \n",
    "    verbose=0, \n",
    "    shuffle=False,\n",
    "    callbacks=[callback, callback_2]\n",
    "    )\n",
    "\n",
    "time_elapsed_BI_LSTM =  time()-t0\n",
    "epochs_used_BI_LSTM = len(history_BI_LSTM.history['loss'])\n",
    "\n",
    "final_train_loss_BI_LSTM = (history_BI_LSTM.history['loss'][-1]*100)\n",
    "final_val_loss_BI_LSTM = (history_BI_LSTM.history['val_loss'][-1]*100)\n",
    "\n",
    "init_train_loss_BI_LSTM = (history_BI_LSTM.history['loss'][0]*100)\n",
    "\n",
    "print(\"Finished in\", time_elapsed_BI_LSTM, \"s using\", epochs_used_BI_LSTM, \"epochs\")\n",
    "\n",
    "y_pred_BI_LSTM = model_BI_LSTM.predict(X_to_predict)\n",
    "\n",
    "y_noscaled = (Y_scaled - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "y_pred_noscale_BI_LSTM = (y_pred_BI_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "yhat_BI_LSTM = model_BI_LSTM.predict(X_scaled)\n",
    "\n",
    "yhat_BI_LSTM_noscale = (yhat_BI_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "df_to_save = df_final.loc[:, (\"Time\", \"PH\")]\n",
    "\n",
    "df_to_save[\"DataType\"] = [\"\" for i in range(len(df_to_save))]\n",
    "\n",
    "for i in range(6, len(df_to_save[6:])):\n",
    "\n",
    "    if df_to_save[\"PH\"].iloc[i].astype('str') == 'nan' :\n",
    "                \n",
    "        df_to_save[\"PH\"].iloc[i] = y_pred_noscale_BI_LSTM[i][0]\n",
    "        df_to_save[\"DataType\"].iloc[i] = \"Prediction\"\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        df_to_save[\"DataType\"].iloc[i] = \"Observation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_noscale_BI_LSTM[:, 0][df_final[\"PH\"][window_size:].astype('str') != 'nan'] = df_final[\"PH\"][window_size:][df_final[\"PH\"][window_size:].astype('str') != 'nan'].values\n",
    "\n",
    "time_delta = df_final[\"Time\"][window_size:] - df_final[\"Time\"][window_size]\n",
    "\n",
    "time_years = np.array([(item / np.timedelta64(1, 'm')) / (60*24*365) for item in time_delta])\n",
    "\n",
    "Y_TREND = y_pred_noscale_BI_LSTM[y_pred_noscale_BI_LSTM.astype('str') != 'nan']\n",
    "X_TREND = time_years[y_pred_noscale_BI_LSTM[:, 0].astype('str') != 'nan']\n",
    "\n",
    "reg = LinearRegression().fit(X_TREND.reshape(-1,1), Y_TREND)\n",
    "\n",
    "slope_BI_LSTM = reg.coef_[0]\n",
    "intercept_BI_LSTM = reg.intercept_\n",
    "\n",
    "print(\"m:\", slope_BI_LSTM, \"n:\", intercept_BI_LSTM)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_BI_LSTM.history['loss'], label='Train loss', lw=3)\n",
    "plt.plot(history_BI_LSTM.history['val_loss'], label='Validation loss', lw=3)\n",
    "\n",
    "plt.text(-1, 0.0075, \"a)\", fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"Loss (MSE)\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.text(epochs_used_BI_LSTM*0.5, init_train_loss_BI_LSTM*0.006, \n",
    "         \"Final train loss: %.2f%%\" % final_train_loss_BI_LSTM, fontsize=16)\n",
    "plt.text(epochs_used_BI_LSTM*0.5, init_train_loss_BI_LSTM*0.005,\n",
    "         \"Final val loss: %.2f%%\" % final_val_loss_BI_LSTM, fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(y_noscaled, lw=3)\n",
    "plt.plot(yhat_BI_LSTM_noscale, lw=3)\n",
    "\n",
    "plt.text(-1, 8.0, \"c)\", fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Training data sequence\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(r\"pH$_\\mathrm{T}$\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(yhat_BI_LSTM, Y_scaled, s=20)\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color='k', lw=3)\n",
    "\n",
    "plt.text(0, 0.9, \"b)\", fontsize=40)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"True values\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "#plt.scatter(X_TREND, Y_TREND, s=1)\n",
    "#plt.plot(X_TREND, slope_BI_LSTM*X_TREND + intercept_BI_LSTM, color='k', lw=3, \n",
    "#         label=r'y=%.4fx + %.4f'% (slope_BI_LSTM, intercept_BI_LSTM))\n",
    "\n",
    "plt.scatter(df_to_save[\"Time\"][df_to_save[\"DataType\"] == \"Observation\"], \n",
    "            df_to_save[\"PH\"][df_to_save[\"DataType\"] == \"Observation\"], s=1, lw=3)\n",
    "\n",
    "plt.scatter(df_to_save[\"Time\"][df_to_save[\"DataType\"] == \"Prediction\"], \n",
    "            df_to_save[\"PH\"][df_to_save[\"DataType\"] == \"Prediction\"], s=1, lw=3)\n",
    "\n",
    "time_delta_plot = df_final[\"Time\"] - df_final[\"Time\"][0]\n",
    "\n",
    "time_years_plot = np.array([(item / np.timedelta64(1, 'm')) / (60*24*365) for item in time_delta_plot])\n",
    "\n",
    "plt.plot(df_to_save[\"Time\"], slope_BI_LSTM*time_years_plot + intercept_BI_LSTM, color='k', lw=3, \n",
    "         label=r'y=%.4fx + %.4f'% (slope_BI_LSTM, intercept_BI_LSTM))\n",
    "\n",
    "plt.text(datetime(2012, 2, 1), 7.98, \"d)\", fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time [years]\", fontsize=30)\n",
    "plt.ylabel(r\"pH$_\\mathrm{T}$\", fontsize=30)\n",
    "\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "#plt.savefig(\"Best_bidirectional_LSTM.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_save.to_csv(\"Palma_data_w_predictions_bis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_BI_LSTM.save('Bidirectional_LSTM_Palma_final_bis.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, min_delta=0.00001)\n",
    "callback_2 = StopCrossPoint()     \n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# design network\n",
    "model_BI_GRU = Sequential()\n",
    "model_BI_GRU.add(Bidirectional(GRU(1, activation='tanh',\n",
    "                              input_shape=(X_train.shape[1], X_train.shape[2]))))\n",
    "model_BI_GRU.add(Dense(1, activation='sigmoid'))\n",
    "model_BI_GRU.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history_BI_GRU = model_BI_GRU.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=500,\n",
    "    steps_per_epoch=10,\n",
    "    #batch_size=100, \n",
    "    validation_data=(X_test, Y_test), \n",
    "    verbose=0, \n",
    "    shuffle=False,\n",
    "    callbacks=[callback, callback_2]\n",
    "    )\n",
    "\n",
    "time_elapsed_BI_GRU =  time()-t0\n",
    "epochs_used_BI_GRU = len(history_BI_GRU.history['loss'])\n",
    "\n",
    "final_train_loss_BI_GRU = (history_BI_GRU.history['loss'][-1]*100)\n",
    "final_val_loss_BI_GRU = (history_BI_GRU.history['val_loss'][-1]*100)\n",
    "\n",
    "init_train_loss_BI_GRU = (history_BI_GRU.history['loss'][0]*100)\n",
    "\n",
    "print(\"Finished in\", time_elapsed_BI_GRU, \"s using\", epochs_used_BI_GRU, \"epochs\")\n",
    "\n",
    "y_pred_BI_GRU = model_BI_GRU.predict(X_to_predict)\n",
    "\n",
    "y_pred_noscale_BI_GRU = (y_pred_BI_GRU - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "yhat_BI_GRU = model_BI_GRU.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_BI_GRU.history['loss'], label='Train loss', lw=3)\n",
    "plt.plot(history_BI_GRU.history['val_loss'], label='Validation loss', lw=3)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"Loss (MSE)\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.text(epochs_used_BI_GRU*0.5, init_train_loss_BI_GRU*0.006,\n",
    "         \"Final train loss: %.2f%%\" % final_train_loss_BI_GRU, fontsize=16)\n",
    "plt.text(epochs_used_BI_GRU*0.5, init_train_loss_BI_GRU*0.005,\n",
    "         \"Final val loss: %.2f%%\" % final_val_loss_BI_GRU, fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(Y_scaled, lw=3)\n",
    "plt.plot(yhat_BI_GRU, lw=3)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"pH\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(yhat_BI_GRU, Y_scaled, s=20)\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color='k', lw=3)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"True values\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(df_final.index, df_final[\"PH\"], s=10)\n",
    "plt.scatter(df_final.index[window_size:], y_pred_noscale_BI_GRU, s=1, color='r')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=30)\n",
    "plt.ylabel(\"pH\", fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "#plt.savefig(\"Best_bidirectional_LSTM.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_noscale_BI_GRU[:, 0][df_final[\"PH\"][window_size:].astype('str') != 'nan'] = df_final[\"PH\"][window_size:][df_final[\"PH\"][window_size:].astype('str') != 'nan'].values\n",
    "\n",
    "time_delta = df_final[\"Time\"][window_size:] - df_final[\"Time\"][window_size]\n",
    "\n",
    "time_years = np.array([(item / np.timedelta64(1, 'm')) / (60*24*365) for item in time_delta])\n",
    "\n",
    "Y_TREND = y_pred_noscale_BI_GRU[y_pred_noscale_BI_GRU.astype('str') != 'nan']\n",
    "X_TREND = time_years[y_pred_noscale_BI_GRU[:, 0].astype('str') != 'nan']\n",
    "\n",
    "reg = LinearRegression().fit(X_TREND.reshape(-1,1), Y_TREND)\n",
    "\n",
    "slope_BI_GRU = reg.coef_[0]\n",
    "intercept_BI_GRU = reg.intercept_\n",
    "\n",
    "print(\"m:\", slope_BI_GRU, \"n:\", intercept_BI_GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results per architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\"RNN\", \"LSTM\", \"Bidirectional LSTM\", \"Bidirectional GRU\"]\n",
    "final_train_losses = [final_train_loss_RNN, final_train_loss_LSTM, final_train_loss_BI_LSTM, final_train_loss_BI_GRU]\n",
    "final_val_losses = [final_val_loss_RNN, final_val_loss_LSTM, final_val_loss_BI_LSTM, final_val_loss_BI_GRU]\n",
    "training_times = [time_elapsed_RNN, time_elapsed_LSTM, time_elapsed_BI_LSTM, time_elapsed_BI_GRU]\n",
    "training_epochs = [epochs_used_RNN, epochs_used_LSTM, epochs_used_BI_LSTM, epochs_used_BI_GRU]\n",
    "trends = [slope_RNN, slope_LSTM, slope_BI_LSTM, slope_BI_GRU]\n",
    "\n",
    "d = {'Architecture':architectures, 'Final training loss':final_train_losses, \n",
    "     'Final validation loss':final_val_losses, 'Training Epochs':training_epochs,\n",
    "     'Training time [s]':training_times, 'Predicted trends':trends}\n",
    "\n",
    "df_results = pd.DataFrame(d)\n",
    "\n",
    "df_results.to_csv(\"Results_window_size_%s.csv\" % window_size)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(X_TREND, (X_TREND * slope + intercept), lw=3, color='k', label=r\"PH$=%.4f$y$ + %.2f$\" % (slope, intercept))\n",
    "plt.scatter(X_TREND, Y_TREND, color='r', s=1)\n",
    "\n",
    "#plt.text(-0.3, 7.92, r\"PH$=-0.011$y$+8.19$\", fontsize=20)\n",
    "\n",
    "plt.xticks(np.arange(0, 9, 1), np.arange(2013, 2022, 1), fontsize=20, rotation=45)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.ylabel(\"PH\", fontsize=30)\n",
    "\n",
    "plt.legend(loc=\"lower left\", fontsize=20)\n",
    "\n",
    "#plt.savefig(\"Trend_Bidirectional_LSTM.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN.save(\"RNN_Palma.h5\")\n",
    "model_LSTM.save('LSTM_Palma.h5')\n",
    "model_BI_LSTM.save('Bidirectional_LSTM_Palma.h5')\n",
    "model_BI_GRU.save('Bidirectional_GRU_Palma.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
