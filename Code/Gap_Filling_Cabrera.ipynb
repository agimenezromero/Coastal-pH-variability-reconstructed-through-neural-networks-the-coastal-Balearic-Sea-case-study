{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_dataset(data, n_times, n_features):\n",
    "    \n",
    "    X = np.zeros((len(data)-n_times, n_times, n_features))\n",
    "    Y = np.zeros(len(data)-n_times)\n",
    "\n",
    "    for i in range(len(data) - n_times):\n",
    "\n",
    "        X[i] = data[i:n_times+i, 0:n_features]\n",
    "        Y[i] = data[n_times+i, -1]\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "def RNN_dataset_pred(data, n_times, n_features):\n",
    "    \n",
    "    X = np.zeros((len(data)-n_times, n_times, n_features))\n",
    "\n",
    "    for i in range(len(data) - n_times):\n",
    "\n",
    "        X[i] = data[i:n_times+i, 0:n_features]\n",
    "        \n",
    "    return X\n",
    "    \n",
    "def preprocessing(data, n_times=24, test_size=0.2):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    scaled = scaler.fit_transform(data)\n",
    "\n",
    "    data_f = scaled\n",
    "    \n",
    "    n_features = data.shape[-1] - 1\n",
    "\n",
    "    X, Y = RNN_dataset(data_f, n_times, n_features)\n",
    "    \n",
    "    idxs = []\n",
    "\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        if str(Y[i]) == 'nan':\n",
    "\n",
    "            idxs.append(i)\n",
    "\n",
    "        else:\n",
    "\n",
    "            j = 0\n",
    "\n",
    "            for item in X[i]:\n",
    "\n",
    "                if str(item[0]) == 'nan' or str(item[1]) == 'nan':\n",
    "\n",
    "                    #print(\"nan found\")\n",
    "                    idxs.append(i)\n",
    "\n",
    "                    break\n",
    "\n",
    "                j+= 1\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    X_new = np.zeros((X.shape[0] - len(idxs), X.shape[1], X.shape[2]))\n",
    "    Y_new = np.zeros(len(Y) - len(idxs))\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        if i not in idxs:\n",
    "\n",
    "            X_new[k] = X[i]\n",
    "            Y_new[k] = Y[i]\n",
    "\n",
    "            k += 1\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y_new, test_size=test_size, random_state=4)\n",
    "    \n",
    "    print(\"Training set:\", X_train.shape, \"Test set:\", X_test.shape)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, scaler, X_new, Y_new\n",
    "\n",
    "class PrintCrossPoint(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_cross = \"\"\n",
    "        self.epoch = 0\n",
    "     \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        self.epoch += 1\n",
    "        \n",
    "        logs = logs or {}\n",
    "        \n",
    "        current_train_loss = logs.get(\"loss\")\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "        \n",
    "        if current_val_loss < current_train_loss:\n",
    "            \n",
    "            if self.epoch_cross == \"\":\n",
    "                self.epoch_cross = self.epoch\n",
    "                \n",
    "            #self.model.stop_training = True\n",
    "            \n",
    "    def on_train_end(self, epoch, logs=None):\n",
    "        \n",
    "        print(\"Validation loss lower than training loss from epoch %s!\" % self.epoch_cross)\n",
    "        \n",
    "class StopCrossPoint(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.epoch = 0\n",
    "     \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        self.epoch += 1\n",
    "        \n",
    "        logs = logs or {}\n",
    "        \n",
    "        current_train_loss = logs.get(\"loss\")\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "        \n",
    "        if current_val_loss < current_train_loss:\n",
    "                \n",
    "            print(\"Training loss higher than validation loss from epoch %s!\" % self.epoch)\n",
    "                \n",
    "            self.model.stop_training = True\n",
    "            \n",
    "def process_cabrera(infilename, outfilename):\n",
    "            \n",
    "    df = pd.read_excel(\"Datos pH Baleares/%s.xlsx\" % infilename, engine=\"openpyxl\")\n",
    "\n",
    "    df.index = df.Time\n",
    "\n",
    "    df_f = df.resample('D').mean()\n",
    "\n",
    "    df_final = df_f[[\"Tempertaure (ÂºC)\", \"Salinity\", \"DO(umol kg-1)\", \"pHTinsitu\"]]\n",
    "\n",
    "    df_final.columns = [\"Temperature\", \"Salinity\", \"Oxygen\", \"PH\"]\n",
    "\n",
    "    df_final.to_csv(\"%s.csv\" % outfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datos pH Baleares/Cabrera.csv\")\n",
    "\n",
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "\n",
    "df_final = df#df[df[\"Time\"] < datetime(2021, 12, 10)]\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_final[\"Time\"], df_final[\"PH\"], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "\n",
    "data_resampled = df_final[df_final[\"Oxygen\"].astype('str') != 'nan'][[\"Temperature\", \"Oxygen\", \"Salinity\", \"PH\"]].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, scaler, X_scaled, Y_scaled = preprocessing(data_resampled, n_times=window_size, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = df_final[[\"Temperature\", \"Oxygen\", \"Salinity\"]].values\n",
    "\n",
    "scaled_new = scaler.min_[0:data_new.shape[-1]] + data_new * scaler.scale_[0:data_new.shape[-1]]\n",
    "\n",
    "n_features = data_new.shape[-1]\n",
    "\n",
    "X_to_predict = RNN_dataset_pred(scaled_new, window_size, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "final_history = 100\n",
    "\n",
    "while final_history > 0.8:\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, min_delta=0.0000005)\n",
    "    callback_2 = StopCrossPoint()     \n",
    "\n",
    "    # design network\n",
    "    model_BI_LSTM = Sequential()\n",
    "    model_BI_LSTM.add(Bidirectional(LSTM(3, activation='tanh',\n",
    "                                  input_shape=(X_train.shape[1], X_train.shape[2]))))\n",
    "    model_BI_LSTM.add(Dense(1, activation='sigmoid'))\n",
    "    model_BI_LSTM.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    # fit network\n",
    "    history_BI_LSTM = model_BI_LSTM.fit(\n",
    "        X_train, \n",
    "        Y_train, \n",
    "        epochs=500,\n",
    "        steps_per_epoch=10,\n",
    "        #batch_size=100, \n",
    "        validation_data=(X_test, Y_test), \n",
    "        verbose=0, \n",
    "        shuffle=False,\n",
    "        callbacks=[callback, callback_2]\n",
    "        )\n",
    "    \n",
    "    final_history = history_BI_LSTM.history['loss'][-1]*100\n",
    "\n",
    "time_elapsed_BI_LSTM =  time()-t0\n",
    "epochs_used_BI_LSTM = len(history_BI_LSTM.history['loss'])\n",
    "\n",
    "final_train_loss_BI_LSTM = (history_BI_LSTM.history['loss'][-1]*100)\n",
    "final_val_loss_BI_LSTM = (history_BI_LSTM.history['val_loss'][-1]*100)\n",
    "\n",
    "init_train_loss_BI_LSTM = (history_BI_LSTM.history['loss'][0]*100)\n",
    "\n",
    "print(\"Finished in\", time_elapsed_BI_LSTM, \"s using\", epochs_used_BI_LSTM, \"epochs\")\n",
    "\n",
    "y_pred_BI_LSTM = model_BI_LSTM.predict(X_to_predict)\n",
    "\n",
    "y_pred_noscale_BI_LSTM = (y_pred_BI_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "y_noscaled = (Y_scaled - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "yhat_BI_LSTM = model_BI_LSTM.predict(X_scaled)\n",
    "\n",
    "yhat_BI_LSTM_noscale = (yhat_BI_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "df_to_save = df_final.loc[:, (\"Time\", \"Temperature\", \"Salinity\", \"Oxygen\", \"PH\")]\n",
    "\n",
    "df_to_save[\"DataType\"] = [\"\" for i in range(len(df_to_save))]\n",
    "\n",
    "for i in range(6, len(df_to_save[6:])):\n",
    "\n",
    "    if df_to_save[\"PH\"][i].astype('str') == 'nan' :\n",
    "                \n",
    "        df_to_save[\"PH\"][i] = y_pred_noscale_BI_LSTM[i][0]\n",
    "        df_to_save[\"DataType\"].iloc[i] = \"Prediction\"\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_to_save[\"DataType\"].iloc[i] = \"Observation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_noscale_BI_LSTM[:, 0][df_final[\"PH\"][window_size:].astype('str') != 'nan'] = df_final[\"PH\"][window_size:][df_final[\"PH\"][window_size:].astype('str') != 'nan'].values\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_BI_LSTM.history['loss'], label='Train loss', lw=3)\n",
    "plt.plot(history_BI_LSTM.history['val_loss'], label='Validation loss', lw=3)\n",
    "\n",
    "plt.text(15, 0.05, \"a)\", fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"Loss (MSE)\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.text(epochs_used_BI_LSTM*0.5, init_train_loss_BI_LSTM*0.006, \n",
    "         \"Final train loss: %.2f%%\" % final_train_loss_BI_LSTM, fontsize=16)\n",
    "plt.text(epochs_used_BI_LSTM*0.5, init_train_loss_BI_LSTM*0.005,\n",
    "         \"Final val loss: %.2f%%\" % final_val_loss_BI_LSTM, fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=20);\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(y_noscaled, lw=3)\n",
    "plt.plot(yhat_BI_LSTM_noscale, lw=3)\n",
    "\n",
    "plt.text(-5, 8.15, \"c)\", fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Training data sequence\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(r\"pH$_\\mathrm{T}$\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(yhat_BI_LSTM, Y_scaled, s=20)\n",
    "plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color='k', lw=3)\n",
    "\n",
    "plt.text(-0.025, 0.9, \"b)\", fontsize=40)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontsize=30, labelpad=10)\n",
    "plt.ylabel(\"True values\", fontsize=30, labelpad=10)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "#plt.scatter(df_final[\"Time\"], df_final[\"PH\"], s=10)\n",
    "\n",
    "plt.scatter(df_to_save[\"Time\"][df_to_save[\"DataType\"] == \"Observation\"], \n",
    "            df_to_save[\"PH\"][df_to_save[\"DataType\"] == \"Observation\"], s=1, lw=3)\n",
    "\n",
    "plt.scatter(df_to_save[\"Time\"][df_to_save[\"DataType\"] == \"Prediction\"], \n",
    "            df_to_save[\"PH\"][df_to_save[\"DataType\"] == \"Prediction\"], s=1, lw=3)\n",
    "\n",
    "plt.text(datetime(2019, 10, 1), 8.155, \"d)\", fontsize=40)\n",
    "\n",
    "plt.xticks(fontsize=16, rotation=30)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.ylabel(r\"pH$_\\mathrm{T}$\", fontsize=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "#plt.savefig(\"bidirectional_LSTM_gap_filling.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.to_csv(\"Cabrera_data_w_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_BI_LSTM.save('Bidirectional_LSTM_Cabrera_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot several predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(df_final[\"Time\"], df_final[\"PH\"], s=10)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, min_delta=0.000001)\n",
    "callback_2 = StopCrossPoint() \n",
    "\n",
    "N_plots = 0\n",
    "\n",
    "while N_plots < 3:    \n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # design network\n",
    "    model_BI_LSTM = Sequential()\n",
    "    model_BI_LSTM.add(Bidirectional(LSTM(3, activation='tanh',\n",
    "                                  input_shape=(X_train.shape[1], X_train.shape[2]))))\n",
    "    model_BI_LSTM.add(Dense(1, activation='sigmoid'))\n",
    "    model_BI_LSTM.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    # fit network\n",
    "    history_BI_LSTM = model_BI_LSTM.fit(\n",
    "        X_train, \n",
    "        Y_train, \n",
    "        epochs=500,\n",
    "        steps_per_epoch=10,\n",
    "        #batch_size=100, \n",
    "        validation_data=(X_test, Y_test), \n",
    "        verbose=0, \n",
    "        shuffle=False,\n",
    "        callbacks=[callback, callback_2]\n",
    "        )\n",
    "\n",
    "    time_elapsed_BI_LSTM =  time()-t0\n",
    "    epochs_used_BI_LSTM = len(history_BI_LSTM.history['loss'])\n",
    "\n",
    "    final_train_loss_BI_LSTM = (history_BI_LSTM.history['loss'][-1]*100)\n",
    "    final_val_loss_BI_LSTM = (history_BI_LSTM.history['val_loss'][-1]*100)\n",
    "\n",
    "    init_train_loss_BI_LSTM = (history_BI_LSTM.history['loss'][0]*100)\n",
    "\n",
    "    print(\"Finished in\", time_elapsed_BI_LSTM, \"s using\", epochs_used_BI_LSTM, \"epochs\")\n",
    "\n",
    "    y_pred_BI_LSTM = model_BI_LSTM.predict(X_to_predict)\n",
    "\n",
    "    y_pred_noscale_BI_LSTM = (y_pred_BI_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "\n",
    "    yhat_BI_LSTM = model_BI_LSTM.predict(X_scaled)\n",
    "\n",
    "    yhat_BI_LSTM_noscale = (yhat_BI_LSTM - scaler.min_[-1]) / scaler.scale_[-1]\n",
    "    \n",
    "    if final_train_loss_BI_LSTM < 0.8:\n",
    "\n",
    "        t = df_final[\"Time\"][window_size:]\n",
    "\n",
    "        t_f = t[(t>datetime(2019,11,15)) & (t<datetime(2020, 7, 1))]\n",
    "        yf = y_pred_noscale_BI_LSTM[(t>datetime(2019,11,15)) & (t<datetime(2020, 7, 1))]\n",
    "\n",
    "        plt.scatter(t_f, yf, lw=3, color='C1', s=1)\n",
    "\n",
    "        plt.text(datetime(2019, 10, 1), 8.155, \"(d)\", fontsize=40)\n",
    "\n",
    "        plt.xticks(fontsize=16, rotation=30)\n",
    "        plt.yticks(fontsize=16)\n",
    "\n",
    "        plt.ylabel(r\"$pH_T$\", fontsize=30)\n",
    "        \n",
    "        N_plots += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 10*np.pi, 0.0001)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "\n",
    "X = np.zeros((len(x)-window_size, window_size, 1))\n",
    "Y = np.zeros(len(x)-window_size)\n",
    "\n",
    "for i in range(len(x) - window_size):\n",
    "\n",
    "    X[i,0:30, 0] = x[i:window_size+i]\n",
    "    Y[i] = y[window_size+i]\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, min_delta=0.000001)\n",
    "callback_2 = StopCrossPoint()     \n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# design network\n",
    "model_BI_LSTM = Sequential()\n",
    "model_BI_LSTM.add(Bidirectional(LSTM(3, activation='tanh', input_shape=(X_train.shape[1],))))\n",
    "model_BI_LSTM.add(Dense(1, activation='sigmoid'))\n",
    "model_BI_LSTM.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history_BI_LSTM = model_BI_LSTM.fit(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    epochs=500,\n",
    "    steps_per_epoch=10,\n",
    "    #batch_size=100, \n",
    "    validation_data=(X_test, Y_test), \n",
    "    verbose=0, \n",
    "    shuffle=False,\n",
    "    callbacks=[callback, callback_2]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
